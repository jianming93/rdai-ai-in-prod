version: '3.9'

services:
  frontend:
    image: frontend:1.0.0
    build:
      context: frontend/
      dockerfile: Dockerfile
      args:
        - GRADIO_SERVER_PORT=7070
    environment:
      - BACKEND_URL=http://backend
      - BACKEND_PORT=9090
      - BACKEND_PROMPT_PATH=/prompt
    expose:
      - 7070
    ports:
      - 7070:7070
    networks:
      - rdai-ai-in-prod-network

  backend:
    image: backend:1.0.0
    build:
      context: backend/
      dockerfile: Dockerfile
    environment:
      - UVICORN_PORT=9090
      - TRITON_SERVER_MODEL_NAME=facebook-opt125m
      - TRITON_SERVER_URL=model-server
      - TRITON_SERVER_PORT=8001
      - TRITON_SERVER_VERBOSE=true
      - TRITON_SERVER_STRAMING_MODE=true
      - TRITON_SERVER_STREAM_TIMEOUT=120
      - TEMPERATURE=0.1
      - TOP_P=0.95
    expose:
      - 9090
    ports:
      - 9090:9090
    networks:
      - rdai-ai-in-prod-network

  # embedder:
  #   image: embedder:1.0.0
  #   build:
  #     context: embedder
  #     dockerfile: Dockerfile
  #   environment:
  #     - EMBEDDER_MODEL=BAAI/bge-large-zh-v1.5
  #     - UVICORN_PORT=6060
  #   expose:
  #     - 6060
  #   ports:
  #     - 6060:6060
  #   networks:
  #     - rdai-ai-in-prod-network

  # data-feed:
  #   restart: on-failure:5
  #   image: data-feed:1.0.0
  #   build:
  #     context: data-feed
  #     dockerfile: Dockerfile
  #   environment:
  #     - REQUEST_INTERVAL=30
  #     - CRYPTOPANIC_URL=https://cryptopanic.com/api/v1/posts
  #     - CRYPTOPANIC_API_TOKEN=8b85ee0e4b49526154c32a7d39f4ce49c9edfbe7
  #     - VECTOR_STORE_URL=vector-store
  #     - VECTOR_STORE_PORT=8000
  #   depends_on:
  #     - vector-store
  #     - embedder
  #   networks:
  #     - rdai-ai-in-prod-network

  model-server:
    image: nvcr.io/nvidia/tritonserver:24.01-vllm-python-py3
    expose:
      - 8000
      - 8001
    ports:
      - 8000:8000
      - 8001:8001
    volumes:
      - ./model-server/model_repository:/opt/tritonserver/model_repository
    command: tritonserver --model-repository /opt/tritonserver/model_repository
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - rdai-ai-in-prod-network

  vector-store:
    image: chromadb/chroma:0.4.22
    expose:
      - 8000
    # ports:
    #   - 8000:8000
    networks:
      - rdai-ai-in-prod-network

  database:
    image: postgres:16.1
    expose:
      - 5432
    environment:
      - POSTGRES_PASSWORD=password # Do not do this is actual prod
    networks:
      - rdai-ai-in-prod-network

  adminer:
    image: adminer:4.8.1
    expose:
      - 8080
    networks:
      - rdai-ai-in-prod-network

networks:
  rdai-ai-in-prod-network:
    driver: bridge