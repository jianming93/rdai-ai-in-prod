version: '3.9'

services:
  frontend:
    image: frontend:1.0.0
    build:
      context: frontend/
      dockerfile: Dockerfile
      args:
        - GRADIO_SERVER_PORT=7070
    environment:
      - BACKEND_URL=http://backend
      - BACKEND_PORT=9090
      - BACKEND_PROMPT_PATH=/prompt
    expose:
      - 7070
    ports:
      - 7070:7070
    networks:
      - rdai-ai-in-prod-network

  backend:
    image: backend:1.0.0
    build:
      context: backend/
      dockerfile: Dockerfile
      args:
        - FASTAPI_SERVER_PORT=9090
    expose:
      - 9090
    ports:
      - 9090:9090
    networks:
      - rdai-ai-in-prod-network
  
  embedder:
    image: embedder:1.0.0
    build:
      context: embedder
      dockerfile: Dockerfile
    environment:
      - EMBEDDER_MODEL=BAAI/bge-large-zh-v1.5
      - UVICORN_PORT=6060
    expose:
      - 6060
    network:
      - rdai-ai-in-prod-network

  model-server:
    image: nvcr.io/nvidia/tritonserver:24.01-vllm-python-py3
    volumes:
      - ./model-server/model_repository:/opt/tritonserver/model_repository
    command: tritonserver --model-repository /opt/tritonserver/model_repository
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - rdai-ai-in-prod-network

  vector-store:
    image: chromadb/chroma:0.4.22
    expose:
      - 8000
    networks:
      - rdai-ai-in-prod-network

  database:
    image: postgres:16.1
    expose:
      - 5432
    networks:
      - rdai-ai-in-prod-network

  adminer:
    image: adminer:4.8.1
    expose:
      - 8080
    networks:
      - rdai-ai-in-prod-network

networks:
  rdai-ai-in-prod-network:
    driver: bridge